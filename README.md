<div align="center">

<img src="https://camo.githubusercontent.com/5b298bf6b0596795602bd771c5bddbb963e83e0f/68747470733a2f2f692e696d6775722e636f6d2f7031527a586a512e706e67" align="center" width="144px" height="144px"/>

### Homelab k8s cluster ‚ò∏

_... automated via [Flux](https://fluxcd.io), [Renovate](https://github.com/renovatebot/renovate) and [GitHub Actions](https://github.com/features/actions)_ ü§ñ

</div>

<div align="center">

[![Discord](https://img.shields.io/discord/673534664354430999?style=for-the-badge&label&logo=discord&logoColor=white&color=blue)](https://discord.gg/k8s-at-home)
[![Talos](https://img.shields.io/badge/v1.5.3-blue?style=for-the-badge&logo=data:image/svg%2bxml;base64,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)](https://www.talos.dev/)
[![Kubernetes](https://img.shields.io/badge/v1.28.2-blue?style=for-the-badge&logo=kubernetes&logoColor=white)](https://k8s.io/)


</div>

---

## üìñ Overview

This is a repository for my home infrastructure and Kubernetes cluster. I try to adhere to Infrastructure as Code (IaC) and GitOps practices using tools like [Terraform](https://www.terraform.io), [Kubernetes](https://kubernetes.io), [Flux](https://fluxcd.io), [Renovate](https://github.com/renovatebot/renovate) and [GitHub Actions](https://github.com/features/actions).

---

## ‚õµ Kubernetes

There is a template over at [onedr0p/flux-cluster-template](https://github.com/onedr0p/flux-cluster-template) if you wanted to try and follow along with some of the practices I use here.

### Installation

This semi hyper-converged cluster runs [Talos Linux](https://talos.dev), an immutable and ephemeral Linux distribution built for [Kubernetes](https://k8s.io), deployed on bare-metal [ThinkCentre M910q](https://www.lenovo.com/us/en/p/desktops/thinkcentre/m-series-tiny/thinkcentre-m910q/11tc1mt910q), [ThinkCentre M720Q](https://www.lenovo.com/id/in/desktops/thinkcentre/m-series-tiny/ThinkCentre-M720q/p/11TC1MTM72Q), and [ThinkCentre M920x](https://www.lenovo.com/us/en/p/desktops/thinkcentre/m-series-tiny/thinkcentre-m920x/11tc1mtm92x). [Rook](https://rook.io) then provides my workloads with persistent block, object, and file storage; while a seperate [TrueNAS Core](https://www.truenas.com/) provides file storage for my media and also S3 and iSCSI.

üî∏ _[Click here](./infrastructure/talos/cluster-0/talconfig.yaml) to see my Talos configuration._

### Core Components

- [actions-runner-controller](https://github.com/actions/actions-runner-controller): Self-hosted Github runners.
- [cilium](https://cilium.io): Internal Kubernetes networking plugin.
- [cert-manager](https://cert-manager.io): Creates SSL certificates for services in my Kubernetes cluster.
- [external-dns](https://github.com/kubernetes-sigs/external-dns): Automatically manages DNS records from my cluster in a cloud DNS provider.
- [external-secrets](https://external-secrets.io): Managed Kubernetes secrets using [1Password Connect](https://github.com/1Password/connect).
- [ingress-nginx](https://github.com/kubernetes/ingress-nginx): Ingress controller for Kubernetes using NGINX as a reverse proxy and load balancer.
- [rook](https://rook.io): Distributed block storage for peristent storage.
- [sops](https://github.com/getsops/sops): Managed secrets for Kubernetes and Terraform which are commited to Git.
- [tf-controller](https://github.com/weaveworks/tf-controller): additional Flux component used to run Terraform from within a Kubernetes cluster.
- [volsync](https://github.com/backube/volsync) and [snapscheduler](https://github.com/backube/snapscheduler): Backup and recovery of persistent volume claims.

### GitOps

[Flux](https://github.com/fluxcd/flux2) watches my [kubernetes](./kubernetes/) folder (see Directories below) and makes the changes to my cluster based on the YAML manifests.

The way Flux works for me here is it will recursively search the [kubernetes/apps](./kubernetes/apps) folder until it finds the most top level `kustomization.yaml` per directory and then apply all the resources listed in it. That aforementioned `kustomization.yaml` will generally only have a namespace resource and one or many Flux kustomizations. Those Flux kustomizations will generally have a `HelmRelease` or other resources related to the application underneath it which will be applied.

[Renovate](https://github.com/renovatebot/renovate) watches my **entire** repository looking for dependency updates, when they are found a PR is automatically created. When some PRs are merged [Flux](https://github.com/fluxcd/flux2) applies the changes to my cluster.

### Directories

This Git repository contains the following directories under [kubernetes](./kubernetes/).

```sh
üìÅ kubernetes      # Kubernetes cluster defined as code
‚îú‚îÄüìÅ bootstrap     # Flux installation
‚îú‚îÄüìÅ flux          # Main Flux configuration of repository
‚îî‚îÄüìÅ apps          # Apps deployed into my cluster grouped by namespace (see below)
```

This Git repository contains the following directories under [infrastructure](./infrastructure/).

```sh
üìÅ infrastructure
‚îú‚îÄüìÅ talos  # Infrastructure defined as code
‚îú‚îÄ‚îÄ‚îÄüìÅ cluster-0     # Cluster-0 code     
‚îî‚îÄ‚îÄ‚îÄüìÅ cluster-1     # Cluster-1 code
```

### Cluster layout

Below is a a high level look at the layout of how my directory structure with Flux works. In this brief example you are able to see that `authelia` will not be able to run until `lldap` and `cloudnative-pg` are running. It also shows that the `Cluster` custom resource depends on the `cloudnative-pg` Helm chart. This is needed because `cloudnative-pg` installs the `Cluster` custom resource definition in the Helm chart.

```python
# Key: <kind> :: <metadata.name>
GitRepository :: k8s-gitops
    Kustomization :: cluster
        Kustomization :: cluster-apps
            Kustomization :: cluster-apps-cloudnative-pg
                HelmRelease :: cloudnative-pg
            Kustomization :: cluster-apps-cloudnative-pg-cluster
                DependsOn:
                    Kustomization :: cluster-apps-cloudnative-pg
                Cluster :: postgres
            Kustomization :: cluster-apps-lldap
                HelmRelease :: lldap
                DependsOn:
                    Kustomization :: cluster-apps-cloudnative-pg-cluster
            Kustomization :: cluster-apps-authelia
                DependsOn:
                    Kustomization :: cluster-apps-lldap
                    Kustomization :: cluster-apps-cloudnative-pg-cluster
                HelmRelease :: authelia
```

### Networking

| Name                         | CIDR              |
|------------------------------|-------------------|
| Kubernetes nodes             | `172.16.13.0/24`  |
| Kubernetes pods              | `10.244.0.0/16`   |
| Kubernetes services          | `10.96.0.0/16`    |
| Kubernetes external services | `172.16.11.0/24`  |

- [cilium](https://github.com/cilium/cilium) is configured with the `io.cilium/lb-ipam-ips` annotation to expose Kubernetes services with their own IP over L3 (BGP), which is configured on my router. L2 (ARP) can also be announced in addition to L3 via the `io.cilium/lb-ipam-layer2` label.
- [cloudflared](https://github.com/cloudflare/cloudflared) provides a [secure tunnel](https://www.cloudflare.com/products/tunnel) for [Cloudflare](https://www.cloudflare.com) to ingress into [ingress-nginx](https://github.com/kubernetes/ingress-nginx), my ingress controller.

üî∏ _[Click here](./kubernetes/apps/networking/cloudflared/app/configs/config.yaml) to see my `cloudflared` configuration._

---

## üåê DNS

<details>
  <summary>Click to see my high level network diagram</summary>

  <img src="assets/dns.svg" align="center" alt="dns"/>
</details>

### Internal DNS

[Juniper SRX340](https://www.juniper.net/us/en/products/security/srx-series/srx340-enterprise-firewall.html) resolves DNS queries via [dnsdist](https://github.com/PowerDNS/pdns/blob/master/pdns/README-dnsdist.md), which provides first-hop DNS resolution for my network and routed based on domain. `DNSDist` forwards requests targeted towards my public domain via [k8s-gateway](https://github.com/ori-edge/k8s_gateway). Last-hop DNS resolution resolves via [1.1.1.1](https://1.1.1.1/dns/), which is configured as my primary DNS upstream provider. If for any reason `dnsdist` becomes unavailable, [Juniper SRX340](https://www.juniper.net/us/en/products/security/srx-series/srx340-enterprise-firewall.html) is configured to fallback to `1.1.1.1` until `dndist` becomes available again.

üî∏ _[Click here](./kubernetes/apps/networking/blocky/app/configs/config.yml) to see my `dnsdist` configuration or [here](./kubernetes/apps/networking/k8s-gateway/app/configs/Corefile) to see my `k8s-gateway` configuration._

### External DNS

[external-dns](https://github.com/kubernetes-sigs/external-dns) is deployed in my cluster and configured to sync DNS records to [Cloudflare](https://www.cloudflare.com/) using ingresses `external-dns.alpha.kubernetes.io/target` annotation.

---

## üîß Hardware

<details>
  <summary>Click to see my rack</summary>

  <img src="assets/rack.png" align="center" alt="rack"/>
</details>

### Active Device

| Device                                   | Count | OS Disk Size | Data Disk Size      | RAM   | Operating System | Purpose                        |
|------------------------------------------|-------|--------------|---------------------|-------|------------------|--------------------------------|
| Juniper SRX340                           | 1     | -            | -                   | -     | -                | Router/FW                      |
| TP-LINK TL-SG3428X                       | 1     | -            | -                   | -     | -                | Aggregation Switch             |
| TP-LINK TL-SG2210MP                      | 1     | -            | -                   | -     | -                | PoE+ Switch                    |
| TP-LINK TL-SX3008F                       | 2     | -            | -                   | -     | -                | 10GbE ToR Switch               |
| Dell PowerEdge R720xd 1x E5-2660v2       | 1     | 500GB SSD    | 12x4TB RAID Z1      | 128GB | TrueNas Core     | iSCSI, NFS, S3                 |
| Elitedesk 400 G1 Mini                    | 1     | 256GB SSD    | -                   | 8GB   | Talos            | Sidero CP                      |
| Thinkcentre M910Q i7 7700T               | 3     | 256GB SSD    | -                   | 32GB  | Talos            | Master & Worker Cluster-0      |
| Thinkcentre M720Q i5 8500  2x10GbE       | 3     | 256GB SSD    | -                   | 32GB  | Talos            | Master Cluster-1               |
| Thinkcentre M720Q i7 8700T 2x10GbE       | 1     | 256GB SSD    | 1x 4TB NVMe         | 64GB  | Talos            | Rook Ceph / Workers Cluster-1  |
| Thinkcentre M920X i7 8700T 2x10GbE       | 2     | 512GB NVMe   | 1x 4TB NVMe         | 64GB  | Talos            | Rook Ceph / Workers Cluster-1  |
| APC SUA 1500VA + 2x 50AH                 | 1     | -            | -                   | -     | -                | Cluster-0 + Network UPS        |
| APC SmartUPS C 1500VA + 2x 12AH          | 1     | -            | -                   | -     | -                | TrueNAS UPS                    |
| APC SmartUPS C 2200VA + 2x 17AH          | 1     | -            | -                   | -     | -                | Cluster-1 UPS                  |
---

### Unused Device

| Device                                   | Count | OS Disk Size | Data Disk Size      | RAM   | Operating System | Purpose                   |
|------------------------------------------|-------|--------------|---------------------|-------|------------------|---------------------------|
| Juniper SRX300                           | 1     | -            | -                   | 4GB   | JunOS            | Router/FW                 |
| Cisco ISR G2 2901                        | 1     | -            | -                   | 2GB   | IOS              | Router/CME                |
| Juniper EX2300-24P                       | 2     | -            | -                   | -     | JunOS            | Switch                    |
| Cisco Catalyst 2960S-48FPS-L             | 1     | -            | -                   | -     | IOS              | Switch                    |
| HPE ProLiant DL380p Gen8 1x E5-2660v2    | 3     | 32GB SD-CARD | 3x DC3610 800GB SSD | 128GB | ESX 7.0u3        | Virtualization + 2x 10GbE |
| Synology DS 1513+  5 Bay                 | 1     | -            | -                   | 8GB   | DSM 7            | -                         |
| Synology DS 1817+  8 Bay                 | 1     | -            | -                   | 16GB  | DSM 7            | -                         |
| Intel NUC7i3BNH                          | 1     | -            | -                   | -     | -                | -                         |
---

## ü§ù Gratitude and Thanks

Thanks to all the people who donate their time to the [Kubernetes @Home](https://discord.gg/k8s-at-home) Discord community. A lot of inspiration for my cluster comes from the people that have shared their clusters using the [k8s-at-home](https://github.com/topics/k8s-at-home) GitHub topic. Be sure to check out the [Kubernetes @Home search](https://nanne.dev/k8s-at-home-search) for ideas on how to deploy applications or get ideas on what you can deploy.

### Inspired By :

- [Buroa K8S GitOps Repo](https://github.com/buroa/k8s-gitops).
- [Carpenike K8S GitOps Repo](https://github.com/carpenike/k8s-gitops).

---

## üìú Changelog

See my _shitty_ [commit history](https://github.com/monosense25/k8s-gitops/commits/main)

---

## üîè License

See [LICENSE](./LICENSE)